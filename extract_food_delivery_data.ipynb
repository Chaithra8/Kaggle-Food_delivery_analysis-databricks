{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c76eb24-5007-46dc-b099-29463b891546",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Extract raw Food_delivery dataset from kaggle and store it as delta table in landing schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a7860706-ffa9-4217-93d7-7ea751e9a74f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting kaggle\n  Downloading kaggle-1.6.17.tar.gz (82 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82.7/82.7 kB 2.5 MB/s eta 0:00:00\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: six>=1.10 in /usr/lib/python3/dist-packages (from kaggle) (1.16.0)\nCollecting certifi>=2023.7.22\n  Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 166.4/166.4 kB 5.6 MB/s eta 0:00:00\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.10/site-packages (from kaggle) (2.8.2)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from kaggle) (2.28.1)\nCollecting tqdm\n  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.5/78.5 kB 4.7 MB/s eta 0:00:00\nCollecting python-slugify\n  Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\nRequirement already satisfied: urllib3 in /databricks/python3/lib/python3.10/site-packages (from kaggle) (1.26.11)\nRequirement already satisfied: bleach in /databricks/python3/lib/python3.10/site-packages (from kaggle) (4.1.0)\nRequirement already satisfied: webencodings in /databricks/python3/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.10/site-packages (from bleach->kaggle) (21.3)\nCollecting text-unidecode>=1.3\n  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.2/78.2 kB 6.6 MB/s eta 0:00:00\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->kaggle) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests->kaggle) (3.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from packaging->bleach->kaggle) (3.0.9)\nBuilding wheels for collected packages: kaggle\n  Building wheel for kaggle (setup.py): started\n  Building wheel for kaggle (setup.py): finished with status 'done'\n  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105789 sha256=a5f635164c42b4bc12b74eb9c486ebe2431edf0d9ce42417eaf9f3da8f5f6fce\n  Stored in directory: /root/.cache/pip/wheels/9f/af/22/bf406f913dc7506a485e60dce8143741abd0a92a19337d83a3\nSuccessfully built kaggle\nInstalling collected packages: text-unidecode, tqdm, python-slugify, certifi, kaggle\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2022.9.14\n    Not uninstalling certifi at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-0f684595-f6a8-45ba-9cd0-ec14625daeee\n    Can't uninstall 'certifi'. No files were found to uninstall.\nSuccessfully installed certifi-2025.1.31 kaggle-1.6.17 python-slugify-8.0.4 text-unidecode-1.3 tqdm-4.67.1\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7defa4be-754e-4f1b-ac9f-0a91b6d36cdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Generate Kaggle API tokens from Kaggle account and upload the JSON file which contains authentication credentials to databricks under \"dbfs:/FileStore/tables/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cea92f4-3cc0-496c-88c5-415409135a73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create directories to store raw food-delivery data\n",
    "dbutils.fs.mkdirs('dbfs:/food_delivery/raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d5b8487-1b4f-428b-a9de-7166e8ea766e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# path of Kaggle token(JSON file) \n",
    "kaggle_token_path = \"dbfs:/FileStore/tables/kaggle_token/kaggle.json\"\n",
    "\n",
    "# To read credentials from json\n",
    "kaggle_token_df = spark.read.format('json').option('header','true').option('inferschema','true').load(kaggle_token_path)\n",
    "\n",
    "# extract the value from the first row of username  & key column\n",
    "KAGGLE_USERNAME = kaggle_token_df.select(kaggle_token_df.username).take(1)[0]['username']\n",
    "KAGGLE_KEY = kaggle_token_df.select(kaggle_token_df.key).take(1)[0]['key']\n",
    "\n",
    "#set credetails as environment variables (or store kaggle.json under '/root/.kaggle/')\n",
    "os.environ['KAGGLE_USERNAME'] = KAGGLE_USERNAME\n",
    "os.environ['KAGGLE_KEY'] = KAGGLE_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23d0d1ff-6c1d-4839-b28a-6e3cfd19992d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully authenticated Kaggle !!\nDataset URL: https://www.kaggle.com/datasets/gauravmalik26/food-delivery-dataset\nfood-delivery-dataset kaggle Dataset downloaded !!\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "# To authenticate kaggle\n",
    "def authenticate_kaggle(KAGGLE_USERNAME, KAGGLE_KEY):\n",
    "  api = KaggleApi()\n",
    "  api.authenticate()\n",
    "  print(\"Successfully authenticated Kaggle !!\")\n",
    "  return api\n",
    "\n",
    "# To download datasets from kaggle api\n",
    "def download_dataset(KAGGLE_USERNAME, KAGGLE_KEY, dataset_name):\n",
    "    # Authenticate kaggle\n",
    "    api = authenticate_kaggle(KAGGLE_USERNAME, KAGGLE_KEY)\n",
    "\n",
    "    #download dataset - this downloads dataset to \"file:/databricks/driver/\"\n",
    "    api.dataset_download_files(dataset_name,unzip=True)\n",
    "\n",
    "    # move dataset to dbfs under \"raw\" folder\n",
    "    dbutils.fs.mv('file:/databricks/driver/train.csv', 'dbfs:/food_delivery/raw/Food_Delivery_dataset.csv')\n",
    "    print(dataset_name.split('/')[1]+\" kaggle Dataset downloaded !!\")\n",
    "\n",
    "\n",
    "dataset_name = \"gauravmalik26/food-delivery-dataset\"\n",
    "# Download datasets from api\n",
    "download_dataset(KAGGLE_USERNAME, KAGGLE_KEY, dataset_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60ccac6d-0e6e-4167-adb0-5bc087fdf478",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now Let's create a 'Landing' schema(database) under default metastore i.e., hive_metastore inorder to store raw data as delta table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75258840-edc6-4ea4-945a-c216c279ce50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": null
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "\n",
    "CREATE DATABASE IF NOT EXISTS landing;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0379be7-b580-48e3-b0cd-914e28819a5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+-------------------+--------------------+--------------------+-----------------+-------------+---------------+-------------------+--------+--------------+--------------+\n|     ID|Delivery_person_ID|Delivery_person_Age|Delivery_person_Ratings|Restaurant_latitude|Restaurant_longitude|Delivery_location_latitude|Delivery_location_longitude|Order_Date|Time_Orderd|  Time_Order_picked|   Weatherconditions|Road_traffic_density|Vehicle_condition|Type_of_order|Type_of_vehicle|multiple_deliveries|Festival|          City|Time_taken_min|\n+-------+------------------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+-------------------+--------------------+--------------------+-----------------+-------------+---------------+-------------------+--------+--------------+--------------+\n|0x4607 |   INDORES13DEL02 |               37.0|                    4.9|          22.745049|           75.892471|                 22.765049|                  75.912471|2022-03-19|   11:30:00|2025-03-10 11:45:00|    conditions Sunny|               High |                2|       Snack |    motorcycle |                0.0|     No |        Urban |      (min) 24|\n|0xb379 |   BANGRES18DEL02 |               34.0|                    4.5|          12.913041|           77.683237|                 13.043041|                  77.813237|2022-03-25|   19:45:00|2025-03-10 19:50:00|   conditions Stormy|                Jam |                2|       Snack |       scooter |                1.0|     No |Metropolitian |      (min) 33|\n|0x5d6d |   BANGRES19DEL01 |               23.0|                    4.4|          12.914264|             77.6784|                 12.924264|                    77.6884|2022-03-19|   08:30:00|2025-03-10 08:45:00|conditions Sandst...|                Low |                0|      Drinks |    motorcycle |                1.0|     No |        Urban |      (min) 26|\n|0x7a6a |  COIMBRES13DEL02 |               38.0|                    4.7|          11.003669|           76.976494|                 11.053669|                  77.026494|2022-04-05|   18:00:00|2025-03-10 18:10:00|    conditions Sunny|             Medium |                0|      Buffet |    motorcycle |                1.0|     No |Metropolitian |      (min) 21|\n|0x70a2 |   CHENRES12DEL01 |               32.0|                    4.6|          12.972793|           80.249982|                 13.012793|                  80.289982|2022-03-26|   13:30:00|2025-03-10 13:45:00|   conditions Cloudy|               High |                1|       Snack |       scooter |                1.0|     No |Metropolitian |      (min) 30|\n|0x9bb4 |    HYDRES09DEL03 |               22.0|                    4.8|          17.431668|           78.408321|                 17.461668|                  78.438321|2022-03-11|   21:20:00|2025-03-10 21:30:00|   conditions Cloudy|                Jam |                0|      Buffet |    motorcycle |                1.0|     No |        Urban |      (min) 26|\n|0x95b4 | RANCHIRES15DEL01 |               33.0|                    4.7|          23.369746|            85.33982|                 23.479746|                   85.44982|2022-03-04|   19:15:00|2025-03-10 19:30:00|      conditions Fog|                Jam |                1|        Meal |       scooter |                1.0|     No |Metropolitian |      (min) 40|\n|0x9eb2 |    MYSRES15DEL02 |               35.0|                    4.6|          12.352058|            76.60665|                 12.482058|                   76.73665|2022-03-14|   17:25:00|2025-03-10 17:30:00|   conditions Cloudy|             Medium |                2|        Meal |    motorcycle |                1.0|     No |Metropolitian |      (min) 32|\n|0x1102 |    HYDRES05DEL02 |               22.0|                    4.8|          17.433809|           78.386744|                 17.563809|                  78.516744|2022-03-20|   20:55:00|2025-03-10 21:05:00|   conditions Stormy|                Jam |                0|      Buffet |    motorcycle |                1.0|     No |Metropolitian |      (min) 34|\n|0xcdcd |    DEHRES17DEL01 |               36.0|                    4.2|          30.327968|           78.046106|                 30.397968|                  78.116106|2022-02-12|   21:55:00|2025-03-10 22:10:00|      conditions Fog|                Jam |                2|       Snack |    motorcycle |                3.0|     No |Metropolitian |      (min) 46|\n+-------+------------------+-------------------+-----------------------+-------------------+--------------------+--------------------------+---------------------------+----------+-----------+-------------------+--------------------+--------------------+-----------------+-------------+---------------+-------------------+--------+--------------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "raw_file_path = \"dbfs:/food_delivery/raw/Food_Delivery_dataset.csv\"\n",
    "# Read the raw data into a DataFrame\n",
    "df_raw = spark.read.option(\"header\", \"true\").csv(raw_file_path, inferSchema=True)\n",
    "\n",
    "# Rename column names, containing invalid characters\n",
    "updated_raw_df = df_raw.withColumnRenamed(\"Time_taken(min)\",\"Time_taken_min\")\n",
    "\n",
    "# Save the raw data as a Delta table in the landing layer\n",
    "updated_raw_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"landing.food_delivery_data\")\n",
    "\n",
    "# view the raw data\n",
    "spark.sql(\"SELECT * FROM landing.food_delivery_data LIMIT 10\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4245348909288000,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "extract_food_delivery_data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
